---
title: 'Lab 15: Final Project'
author: "Brian Teklits, Charles Doremieux, Andrew MacLean, Clint LaBattaglia"
date: "12/16/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE,message=FALSE)
library(modelr)
library(tidyverse)
library(maps)
library(lubridate)
# install.packages("openintro")
library(openintro)
# Data from: https://www.kaggle.com/sobhanmoosavi/us-accidents
# LARGE: do not upload to github
accidents <- read_csv("US_Accidents_May19.csv")

```

## Main Question

**Domain Expert and Dataset:**

The domain expert is the NHTSA, the National Highway Traffic Safety Administration.

The dataset we are using can be found [here.](https://www.kaggle.com/sobhanmoosavi/us-accidents) It contains 2.25 million records of accidents from 49 different states, starting in February 2016 until March 2019. It includes data on the severity of the accident, where and when the accident occurred, the weather at the time of the accident, and various information about the nearby surroundings. 

**Main Question & it's Importance:**
Lead with your main overall question, why it’s important (and why those reasons are important), 

**Answer:**
your answer/conclusion, 
**Recommendation:**
```{r}

```

recommendation, and a plot communicating your conclusion or basis for your recommendation. 

## Individual Sections

Each teammate must apply “recently learned” programming tools to answer a subquestion that will help your team answer the overall question. The subquestions must be different from the overall team question. Each subquestion should get its own subsection in the team report and should follow the format for statistical analyses that we have learned in class.

What is the question? Why is it important/interesting?

What new tools did you use?

What is the answer to the question? How does this relate to the overall question?

What are the ethical implications of your findings, conclusions, or recommendations?

### Andrew

### Brian

### Charles

My goal is to determine if there is a positive relationship between Humidity and the duration of an accident. My intuition is that the more humidity, the less traction there will be on the road, shortening the length of an accident. The duration of an accident can help suggest the severity of the accident and the effect it will have on the flow of traffic. My expectation is that if I can demonstrate that Humidity is positively or negatively associated with accident duration, I can make a determination on which states are the most likely to have short or long accidents.

First I need to create a model of the time an accident takes and seperate outlier values.
```{r}
cd_data <- accidents %>%
  mutate(a_start = ymd_hms(Start_Time)) %>%
  mutate(a_end = ymd_hms(End_Time)) %>%
  mutate(accident_time = difftime(a_end, a_start, units = "mins")) %>%
  filter(!is.na(`Humidity(%)`), !is.na(accident_time)) %>%
  filter(accident_time >= 0 & accident_time <= 4320) %>%
  select(a_start, a_end, accident_time, `Humidity(%)`)
```

The model needs to include predictions and residuals.
```{r}
humid_time_model <- lm(cd_data$accident_time ~ `Humidity(%)`, data = cd_data)

humid_preds <- cd_data %>%
  data_grid(`Humidity(%)` = seq_range(`Humidity(%)`, 2178823)) %>%
  add_predictions(humid_time_model,'predictions') %>%
  add_residuals(humid_time_model, 'residuals')
```

The view of the raw data.
```{r}
ggplot() +
  geom_point(data = cd_data, aes(`Humidity(%)`,accident_time))+
  ggtitle("View of Humidity as it Relates to Accident Duration")+
  xlab("Humidity (%)")+
  ylab("Accident Time (minutes)")
```

Predictions of the data.
```{r}
ggplot()+
  geom_line(data = humid_preds, aes(`Humidity(%)`, humid_preds$predictions))+
  ggtitle("Predictions of Humidities Related to Accident Duration")+
  xlab("Humidity (%)")+
  ylab("Accident Time (minutes)")
```

```{r}
ggplot()+
  geom_line(data = humid_preds, aes(`Humidity(%)`, humid_preds$residuals))+
  ggtitle("Residuals of Humidities Related to Accident Duration")+
  xlab("Humidity (%)")+
  ylab("Accident Time (minutes)")
```

```{r}
# perm_mean <- function(perms = 1000, x, y)
# {
#   perm_mean_diffs2 <- numeric(perms)
#   
#   for(i in c(1:perms))
#   {
#     rand_order_y <- sample(y)
#     cor_comp <- cor(x,rand_order_y)
#     perm_mean_diffs2[i] <- cor_comp
#   }
#   return(perm_mean_diffs2)
# }
# 
# cc <- perm_mean(1000, cd_data$`Humidity(%)`, as.numeric(cd_data$accident_time))

```

The model confirms my suspicion that as the Humidity(%) increases the length of an accident shortens, though the model is not absolute in its certainty. Nevertheless there is a general trend to shorter accidents when Humidity is high. The model suggests Humidity can be used to predict the duration of an accident by: -0.2375825(Humidity) with the intercept 111.0417.

### Clint
Question Ideas: Explore relationship between severity of accidents and stoplights + percentage of accidents with each of the binary variables. 
uses map functino to take percentiles if true false sections and graph + permutation test to see if there is correlation between severity of accident and presence of stoplight or just most common accident indicator +
Question: Which of the true/false variables is the greatest predictor of an accident, and are any of them related to a the probability of a more severe accident? This question is important/interesting because if a majority of accidents occur near specific locations, like a traffic signal or railway crossing then  countermeassures like positioning police vehicles nearby or placing extra warning signs in the area can be put in place which may save lives. Also if some presences are especially indicative of more severe accidents, those area could be targeted for increased safty measures. 

First I want to examine the percentage of total accidents associated with each of the true/false columns so  created a for loop which calculated the percentage of total accidents which had a true response for each of the columns and stored it in a dataframe called sums_true.
```{r}
library(knitr)
explore <- accidents%>%
  select(Amenity, Bump, Crossing, Give_Way, Junction, No_Exit, Railway, Roundabout, Station, Stop, Traffic_Calming, Traffic_Signal, Turning_Loop)

sums_true <- data.frame(mode = "double", ncol(explore))
for (i in seq_along(explore)) {
  sums_true[i] <- (sum(explore[[i]])/tally(accidents))*100
}
```
From there I can see that eight of the thirteen variables are true in less than 1 percent of observed accidents so, while that doesn't make them negligable, I would prefer to focus on the more significant variables. It is also worth noting that the total of all percentages added together is 34.66% which means 65.34% of accidents didn't have any of the true/false variable associated with them.  

```{r}
ggplot(data = sums_true) + geom_col(aes(x= 1, y = sums_true$n.9, fill = "Traffic Signal"))+
  geom_col(aes(x= 2, y = sums_true$n.2, fill = "Junction")) +
  geom_col(aes(x = 3, y = sums_true$n, fill = "Crossing"))+
  geom_col(aes(x = 4, y = sums_true$n.6, fill = "Station"))+
  geom_col(aes(x = 5, y = sums_true$mode, fill = "Amenity"))+
  ggtitle("Top Five Presence at Accident Percentages")+
  ylab("Percent of Accidents Present")+
  xlab("Rank")
```
So I now know that the three highest presences by far are traffic signals, junctions, and crossings. Now I'm curious if any of these variables have an effect on the average severity of an accident. 
```{r}
traffic_true<- accidents%>%
  filter(Traffic_Signal == "TRUE")
Junction_true <-accidents%>%
  filter(Junction == "TRUE")
crossing_true <-accidents%>%
  filter(Crossing == TRUE)
without_boolean <- accidents%>%
  filter(Amenity == FALSE, Bump == FALSE, Crossing  == FALSE, Give_Way == FALSE, Junction == FALSE, No_Exit == FALSE, Railway == FALSE, Roundabout == FALSE, Station == FALSE, Stop == FALSE, Traffic_Calming == FALSE, Traffic_Signal == FALSE, Turning_Loop == FALSE)

mean1 <- mean(accidents$Severity)
mean2 <-mean(traffic_true$Severity)
mean3 <-mean(Junction_true$Severity)
mean4 <-mean(crossing_true$Severity)
mean5 <-mean(without_boolean$Severity)
```

```{r}
ggplot()+ geom_col(aes(x= 1, y = mean3, fill = "Junction")) +
  geom_col(aes(x = 2, y = mean5, fill = "Average severity without True/False"))+
  geom_col(aes(x= 3, y = mean1, fill = "Unfiltered Average Severity"))+
  geom_col(aes(x=4, y = mean2, fill = "Traffic Signal" ))+
  geom_col(aes(x=5, y=mean4, fill = "Crossing"))+
  ggtitle("Average Severity Across Top Three Acident Presences")+
  ylab("Mean Severity")+
  xlab("Rank")
```

busted function
```{r}
calc_severity <- function(data, var_name1, var_name2){
new_data <-  filter_(data$var_name1 == "TRUE")
  mean_severity <- mean(new_data$var_name2)
  return(mean_severity)
}
calc_severity(accidents, accidents$Traffic_Signal, accidents$Severity)
```

New Tools: The primary new tool in R that I used was a for loop in order to  gather the percentages of the total observed accidents with for of the True/False variables. I used a for loop because a map function would not work, I needed to produce a new dataframe with a rowcount of one(the percentage of total accidents) whereas map functions preserve the number of rows. 
Conclusions: From my analysis I can see that the most common indicator is no indicator at all, implying that the majority of accidents either occured in open road not near any features or that the majority of nearby features were not reported in the dataset. However, of the observed indicators, traffic signals, junctions, and crossings accounted for 29.76% of total accidents which is a pretty significant amount. Traffic singals had far and away the highest individual percentage at 15.98%. This leads me to recomend that a public saftey campaign be run that warns people about the dangers of not paying proper attention at traffic signals. Severity is a measure of how impactful the accident was to the flow of traffic, not inherently how destructive a accident is as the name may imply. Consequetially, since Junctions and no observed features had the highest average severity by a fairly large margin I would recommend that machinery and tow trucks used to clear the road after accidents be stored near junctions as this would help to reduce the effect of the accidents on traffic by lowering response time.  
## Reflections on Lab 2

As a team, restate your team’s goal(s) and reflect on how well you achieved it. If you could travel back in time, which is one thing you would tell your team to keep doing? Stop doing? Start doing? Discuss this as a team and add it as a section to your Final Project.

Our team goals were to do well in the course, gain a greater understanding of the use of R and of data science in general, and not make any enemies. We can say with confidence that we accomplised the first two goals. The third may have been a little less successful. If we could travel back in time, there are three things we would do differently. First, we would meet up more often in order to work on the project in a more collaborative fashion rather than individuals doing their sections on their own. Second, we would make more productive use of our time in class as an oppurtunity to deepen our understanding of the material by asking more questions of the profesor. Third, we would communicate more often about not only the labs but the readings to ensure that everyone is at a similar comfort level with new applications and statistical applications. While this was a successful semester for our group in terms of observed grades, there was still room for improvement in the areas of teamwork, communication, and understanding of the material. 
### Individual Reflections

Individually, write a paragraph reflecting on: how have your six-month or 5-year goals changed? What did you learn/accomplish in this course? If you could give yourself advice at the beginning of the semester, what would you tell yourself to keep doing, stop doing, and start doing?

**Andrew:**

**Brian:**

**Charles:** 
  My original 6-month and five-year year plans have not changed, but my attitudde towards them has certainly changed. I still want to study under some of the greatest voices in philosophy (one of my majors) while working towards some meaningful contribution within my fields of interest. I have been working towards those goals and this semester was invited to take PHIL 6380 (Graduate Metaphysics) by a professor. I have set my eyes on my 5 year goal, and I am very nervous about it. I hope I can achieve what I'm setting out for, though I am nervous I'll fail. I learned a lot about project managing mainly because I've failed a lot this semester. I struggled to manage and process my internal stress and translate it to success externally. These are things I would have liked to work on more. Furthermore, I needed to motivate myself to learn outside of the classroom. I was very dependent on the help of my team-mates and I wish I could have been more independent.

**Clint:**
  Since the beginning of the semester my 6-month to five-year goals have changed in that I have less confidence my ability to thrive in a coding driven profession than I had at the beginnning of the semester. This is useful information to know as I have been considering going into a business masters program in which coding and statistics would feature prominently. Now I am wondering if this is the right path after all. In this course I learned what feels like the basics of programming in R, though I am not a proficcient as a I could or should be, and I also feel as though I learned about the basics of statistics in general which has been really interesting. If I could past me advice I would tell myself to do all the exercises when going through the R4DS textbook, experiment when doing the labs instead of doing the bare minimum, communicate more concisely with my teammates, and go to office hours w/ the professor and TAs.
### Individual Contributions

**Andrew:**

**Brian:**

**Charles:** 
  I used various modelr methods to calculate several predictions and residuals for our linear models. I also split data into model building and model validation subsets. By incorporating variable transformations I was able to draw a conclusion on the interactions between Humidity and the period for which an accident lasts.


**Clint:**
